{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms used for the thesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook I saved the algorithms used for my thesis. \n",
    "In this file is presented only the code used. For a better explaination of the algorithms, results and problem related to the implementation the reader is invited to look at the third chapter of my thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import scipy.spatial as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplex Projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To calculate the volume of a simplex I used the algorithm found [here](https://mathworld.wolfram.com/Cayley-MengerDeterminant.html), which uses the Cayley-Menger determinant.\n",
    "\n",
    "To check if the point is contained in a simplex I used an algorithm that uses the barycentric coordinates found [here](https://math.stackexchange.com/questions/1226707/how-to-check-if-point-x-in-mathbbrn-is-in-a-n-simplex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "def nCr(n,r):\n",
    "    \"\"\"class that given 2 positive integer, return the number of combinations\"\"\"\n",
    "    f = math.factorial\n",
    "    return f(n) / f(r) / f(n-r)\n",
    "\n",
    "def cayley_menger_determinant(matrix,E_dim):\n",
    "    \"\"\"cayley menger determinant: hypervolume of an irregular simplex:\\n\n",
    "        matrix - irregular simplex\n",
    "        E_dim - dimension of the irregular simplex\n",
    "    \"\"\"\n",
    "    dist_matrix = np.zeros((E_dim+1,E_dim+1))\n",
    "    for i in range(E_dim+1):\n",
    "        for j in range(E_dim+1):\n",
    "            dist_matrix[i][j]=np.linalg.norm(matrix[i]-matrix[j])**2\n",
    "    addc=np.ones(E_dim+1)\n",
    "    addr=np.ones(E_dim+1)\n",
    "    addr=np.insert(addc, 0, 0)\n",
    "    B=np.column_stack((addc,dist_matrix))\n",
    "    B=np.vstack((addr,B))\n",
    "\n",
    "    vol=abs( np.linalg.det(B)/( 2**E_dim * math.factorial(E_dim)**2 ) )\n",
    "    vol=math.sqrt(vol)\n",
    "    return vol\n",
    "\n",
    "\n",
    "class Simplex_Projection:\n",
    "    \"\"\"Sugihara_and_May_algorithm class\"\"\"\n",
    "\n",
    "    def __init__(self, matrix, N, E_dim, m_bool):\n",
    "        \"\"\"\n",
    "        SP class constructor.\\n\n",
    "        matrix (N-E+1,E) - whose rows are points in embedding dimension;\\n\n",
    "        N - longness of time serie;\\n\n",
    "        E_dim - dimension of each point;\n",
    "        m_bool - if m_bool=0 means that the matrix need to be built \n",
    "                 overlapping the time series.\n",
    "                 if m_bool=1 the matrix need to be built not overlapping the time serie\n",
    "        accepted - int that counts the number of times \"prediction's method\" finds a simplex for a point\n",
    "        attempted - int that counts the number of times \"prediction's method\" is called\n",
    "        in - boolean variable if is true the point is in the simplex, if it is false is out of the simplex\n",
    "        \"\"\"\n",
    "        self.matrix = matrix\n",
    "        self.N = N\n",
    "        self.E_dim = E_dim\n",
    "        self.bool = m_bool\n",
    "        self.accepted=0\n",
    "        self.attempted=0\n",
    "        self.inside=0\n",
    "        \n",
    "    def get_acceptance(self):\n",
    "        print(f'self.attempted: {self.attempted}')\n",
    "        print(f'self.accepted: {self.accepted}')\n",
    "        if(self.attempted==0):\n",
    "            return 0\n",
    "        return self.accepted/self.attempted\n",
    "        \n",
    "    def check_inside_simplex(self,Vector,matrix):\n",
    "        \"\"\" method used to verify if a point 'Vector' is inside a simplex 'matrix' \"\"\"\n",
    "        assert matrix[0].size == self.E_dim and matrix[:,0].size == self.E_dim + 1\n",
    "        \n",
    "        #Building the cm-basis of R^E of our simplex\n",
    "        basis_cm = np.zeros((self.E_dim,self.E_dim))\n",
    "        for i in range(self.E_dim):\n",
    "            for j in range(self.E_dim):\n",
    "                basis_cm[i][j] = matrix[i+1][j] - matrix[0][j]\n",
    "    \n",
    "        basis_cm=np.transpose(basis_cm)\n",
    "        \n",
    "        #Writing a vector in cm coordinates\n",
    "        vector_cm = np.zeros(self.E_dim)\n",
    "        for i in range(self.E_dim):\n",
    "            vector_cm[i] = Vector[i] - matrix[0][i]\n",
    "            \n",
    "        #Solution is the vector of coefficients of our linear system if the rank is maximum, otherwise is the coefficient that minimize the mse    \n",
    "        solution=np.linalg.lstsq(basis_cm, vector_cm)\n",
    "        sum_solution=0.0\n",
    "        cont=0\n",
    "        for i in range(self.E_dim):\n",
    "            sum_solution = sum_solution + solution[0][i]\n",
    "            if(solution[0][i] >= 0):\n",
    "                cont = cont +1 \n",
    "        #those are the sufficient and necessary conditions to check if the point is in the simplex        \n",
    "        if( cont == self.E_dim and sum_solution <= 1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "        \n",
    "    \n",
    "    def Exponetial_Weighted_Prediction(self, Vector, step):\n",
    "        \"\"\"It generates the prediction of some \"step\" in the future of \"Vector\" making the exponetial-weighted average of the simplex\"\"\"\n",
    "        assert Vector.size == self.E_dim\n",
    "        if( self.bool == True):\n",
    "            assert self.N % self.E_dim == 0\n",
    "            long = int(self.N/self.E_dim)\n",
    "            \n",
    "        else:\n",
    "            long = self.N - self.E_dim + 1\n",
    "            \n",
    "        #Copying the matrix in matrix_shorter\n",
    "        matrix_shorter = self.matrix\n",
    "        \n",
    "        #Deleting the last step_future rows of the matrix because the state space doesn't have their projection in the future\n",
    "        for i in range(step):\n",
    "            matrix_shorter = np.delete(matrix_shorter, matrix_shorter[:,0].size-1,axis=0) \n",
    "           \n",
    "        #Calculating the distances between Vector and the points of the state space\n",
    "        distance = np.zeros(long-step) \n",
    "        for i in range (long-step):\n",
    "            sum=0.0\n",
    "            for k in range (self.E_dim):\n",
    "                sum=(Vector[k] - matrix_shorter[i][k])**2\n",
    "            distance[i] = math.sqrt(sum)\n",
    "        \n",
    "        #Arg-sorting the vector of distances\n",
    "        v_times = np.argsort(distance) \n",
    "        #Ordering the vector of distances that will be used to make the estimation of the prediction\n",
    "        distance = np.sort(distance) \n",
    "        \n",
    "        \n",
    "        \"\"\"the next part needs to find the smallest simplex around the point\"\"\"\n",
    "        check = 0\n",
    "        self.attempted +=1\n",
    "        while True:\n",
    "            #Copying v_times in a smaller array\n",
    "            v_times_check = v_times[0:self.E_dim+1+check]\n",
    "            #Creating the combinations\n",
    "            comb = combinations(v_times_check, self.E_dim+1)\n",
    "            #Number of combinations\n",
    "            Num_comb=int(nCr(v_times_check.size,self.E_dim+1))\n",
    "            #Vector which contain the index of the combination k; k=0,...,Num_comb-1\n",
    "            ordering_combinations = np.arange(Num_comb)\n",
    "            volume_simplexes = np.empty(0)\n",
    "            \n",
    "            iterator_k=0\n",
    "            number_deletes=0\n",
    "            \n",
    "            if ( Num_comb >1500 ):\n",
    "                #If Num_comb >1500 the algorithm becomes a KNN with K=E\n",
    "                v_times = v_times[0:self.E_dim]\n",
    "                self.inside=0\n",
    "                break    \n",
    "                \n",
    "            #I search the simplex in all the E+1 combination of the K nearest neighbors\n",
    "            for k in list(comb):\n",
    "                \n",
    "                #Considering the combination k, and than checking if it contains the point\n",
    "                v_times_check_current = np.asarray(k)\n",
    "            \n",
    "                #Saving the combination in matrix_simplex\n",
    "                matrix_simplex = np.zeros((self.E_dim+1,self.E_dim))\n",
    "                for i in range(self.E_dim+1):\n",
    "                    for j in range(self.E_dim):\n",
    "                        iterator = int(v_times_check_current[i])\n",
    "                        matrix_simplex[i][j] = matrix_shorter[iterator][j]\n",
    "               \n",
    "                #Checking if Vector is contained in matrix_simplex\n",
    "                if( self.check_inside_simplex( Vector, matrix_simplex ) ):\n",
    "                    \"\"\"if the point is in the simplex i calculate the volume of it\"\"\"\n",
    "                    #Saving the volumes of the simplexes in volume_simplexes\n",
    "                    vol = cayley_menger_determinant(matrix_simplex,self.E_dim)\n",
    "                    volume_simplexes=np.append(volume_simplexes,vol)\n",
    "                else:\n",
    "                    if( ordering_combinations.size != 0 ):\n",
    "                        ordering_combinations = np.delete(ordering_combinations,iterator_k-number_deletes)\n",
    "                        number_deletes+=1\n",
    "                iterator_k=iterator_k+1\n",
    "                \n",
    "            #If it is true, means the algorithm found at least one simplex that contain the point\n",
    "            if( ordering_combinations.size != 0 ):\n",
    "                self.accepted +=1\n",
    "                self.inside=1\n",
    "                \n",
    "                #Create a matrix with 2 columns \n",
    "                #The first contain the number of the combination, the second the correspective volume\n",
    "                vol_oredering =  np.column_stack((ordering_combinations,volume_simplexes))\n",
    "                #Sorting the rows by the volume (i.e. by the second column)\n",
    "                vol_oredering = vol_oredering[np.argsort(vol_oredering[:, 1])]\n",
    "               \n",
    "                #The index of the combination of the smallest volume\n",
    "                smallest_simplex_combination = vol_oredering[0][0]\n",
    "                #\"contatore\" counts the index of the combinations in the next loop \"for\"\n",
    "                #At the end of the loop \"contatore\" is equal to the index of the combination of the smallest simplex\n",
    "                contatore=0\n",
    "                #\"v_times\" saves the time steps of the combination of the simplex\n",
    "                v_times=np.empty(0)\n",
    "                comb2 = combinations(v_times_check, self.E_dim+1)\n",
    "                for j in list(comb2):\n",
    "                    if( contatore == smallest_simplex_combination ):\n",
    "                        v_times = np.asarray(j)\n",
    "                        break\n",
    "                    contatore = contatore + 1\n",
    "    \n",
    "                break\n",
    "            check=check+1\n",
    "                    \n",
    "        \"\"\"the simplex is built\"\"\"\n",
    "        long_simplex=0\n",
    "        if(self.inside):\n",
    "            #If self.inside is True Vector is contained in the simplex\n",
    "            long_simplex=self.E_dim+1\n",
    "        else:\n",
    "            #Otherwise the method becomes a KNN with K=E\n",
    "            long_simplex=self.E_dim\n",
    "            \n",
    "        #Saving the values of the simplex    \n",
    "        simplex = np.zeros((long_simplex,self.E_dim))\n",
    "        for i in range (long_simplex):\n",
    "            for j in range (self.E_dim):\n",
    "                iteratore=int(v_times[i])\n",
    "                simplex[i][j]= matrix_shorter[iteratore][j]\n",
    " \n",
    "        #time steps of the new simplex which contains \"Vector\"\n",
    "        v_times_prediction = np.zeros(long_simplex)\n",
    "        for i in range (v_times.size):\n",
    "            v_times_prediction[i]=v_times[i]+step\n",
    "         \n",
    "        #\"prediction\" is the E-dimensional vector returned by the algorithm\n",
    "        prediction = np.zeros(self.E_dim)\n",
    "        #\"matrix_prediction\" contains the points which form the simplex\n",
    "        matrix_prediction = np.zeros((long_simplex,self.E_dim))\n",
    "        for i in range (long_simplex):\n",
    "            for j in range (self.E_dim):\n",
    "                iter=int(v_times_prediction[i])\n",
    "                matrix_prediction[i][j]= self.matrix[iter][j]\n",
    "          \n",
    "        #Making the exponential weighted average\n",
    "        for i in range (self.E_dim):\n",
    "            sum=0.\n",
    "            den=0.\n",
    "            for j in range (long_simplex):\n",
    "                sum+=matrix_prediction[j][i]*math.exp(-distance[j])\n",
    "                den+=math.exp(-distance[j])\n",
    "            sum = sum/den\n",
    "            prediction[i]=sum\n",
    "            \n",
    "        return prediction \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"KNN algorithm class\"\"\"\n",
    "\n",
    "    def __init__(self, matrix, N, E_dim, K):\n",
    "        \"\"\"\n",
    "        KNN class constructor.\\n\n",
    "        matrix (N-E+1,E) - whose rows are points in embedding dimention;\\n\n",
    "        N - longness of time serie;\\n\n",
    "        E_dim - dimension of each point;\n",
    "        K - number of neighbors\n",
    "        \"\"\"\n",
    "        self.matrix = matrix\n",
    "        self.N = N\n",
    "        self.E_dim = E_dim\n",
    "        self.K=K\n",
    "        \n",
    "        \n",
    "\n",
    "    def Ave_Prediction(self, Vector, step):\n",
    "        \"\"\"It generates prediction of some step in the future making the unweighted-average of the neighbours\"\"\"\n",
    "        assert Vector.size == self.E_dim\n",
    "            \n",
    "        #Copying the matrix in matrix_shorter    \n",
    "        matrix_shorter = self.matrix\n",
    "        \n",
    "        #Deleting the last step_future rows of the matrix because the state space doesn't have their projection in the future\n",
    "        for i in range(step):\n",
    "            matrix_shorter = np.delete(matrix_shorter, matrix_shorter[:,0].size-1,axis=0)\n",
    "            \n",
    "        #Calculating the distances between Vector and the points of the state space\n",
    "        distance = np.zeros(self.N-self.E_dim+1-step)\n",
    "        for i in range (self.N-self.E_dim+1-step):\n",
    "            sum=0.0\n",
    "            for k in range (self.E_dim):\n",
    "                sum=(Vector[k] - matrix_shorter[i][k])**2\n",
    "            distance[i] = math.sqrt(sum)\n",
    "            \n",
    "        #Arg-sorting the vector of distances\n",
    "        v_times = np.argsort(distance)\n",
    "        #Ordering the vector of distances that will be used to make the estimation of the prediction\n",
    "        distance = np.sort(distance)\n",
    "        \n",
    "        for i in range (self.K,v_times.size):\n",
    "            #Keeping only the first K points\n",
    "            v_times = np.delete(v_times,self.K)\n",
    "            distance = np.delete(distance,self.K)\n",
    "       \n",
    " \n",
    "        v_times_prediction = np.zeros(self.K)\n",
    "        for i in range (v_times.size):\n",
    "            #Time steps of the first K neighbors\n",
    "            v_times_prediction[i]=v_times[i]+step\n",
    "         \n",
    "        \n",
    "        #Keeping the values of K neigbors in matrix_predictee\n",
    "        prediction = np.zeros(E)\n",
    "        matrix_prediction = np.zeros((self.K,E))                \n",
    "        for i in range (self.K):\n",
    "            for j in range (self.E_dim):\n",
    "                iter=int(v_times_prediction[i])\n",
    "                matrix_prediction[i][j]= self.matrix[iter][j]\n",
    "                \n",
    "        #The arithmetical average of the k-nearest neighbors is the estimation of the prediction: the \"predictee\"   \n",
    "        for i in range (self.E_dim):\n",
    "            sum=0\n",
    "            for j in range (self.K):\n",
    "                sum+=matrix_prediction[j][i]\n",
    "            sum = sum/(self.K)\n",
    "            prediction[i]=sum\n",
    "            \n",
    "        return prediction \n",
    "    \n",
    "    \n",
    "    def Exponetial_Weighted_Prediction(self, Vector, step):\n",
    "        \"\"\"It generates prediction of some step in the future making the exponetial-weighted average of the neighbours\"\"\"\n",
    "        assert Vector.size == self.E_dim\n",
    "        \n",
    "        #\"long\" are the number of points in the state space\n",
    "        long = self.N - self.E_dim + 1\n",
    "            \n",
    "        #Copying the matrix in \"matrix_shorter\"\n",
    "        matrix_shorter = self.matrix \n",
    "        \n",
    "        #Deleting the last step_future rows of the matrix because the state space doesn't have their projection in the future\n",
    "        for i in range(step):\n",
    "            matrix_shorter = np.delete(matrix_shorter, matrix_shorter[:,0].size-1,axis=0) \n",
    "            \n",
    "        #Calculating the distances between Vector and the points of the state space\n",
    "        distance = np.zeros(long-step) \n",
    "        for i in range (long-step):\n",
    "            sum=0.0\n",
    "            for k in range (self.E_dim):\n",
    "                sum=(Vector[k] - matrix_shorter[i][k])**2\n",
    "            distance[i] = math.sqrt(sum)\n",
    "        \n",
    "        #Arg-sorting the vector of distances\n",
    "        v_times = np.argsort(distance) \n",
    "        #Ordering the vector of distances that will be used to make the estimation of the prediction\n",
    "        distance = np.sort(distance) \n",
    "        \n",
    "        for i in range (self.K,v_times.size):\n",
    "            #Keeping only the first K points\n",
    "            v_times = np.delete(v_times,self.K) \n",
    "            distance = np.delete(distance,self.K) \n",
    "       \n",
    " \n",
    "        v_times_prediction = np.zeros(self.K)\n",
    "        for i in range (v_times.size):\n",
    "            #Time steps of the first K neighbors\n",
    "            v_times_prediction[i]=v_times[i]+step \n",
    "         \n",
    "        #Keeping the values of K neigbors in matrix_predictee\n",
    "        prediction = np.zeros(self.E_dim)\n",
    "        matrix_prediction = np.zeros((self.K,self.E_dim)) \n",
    "        for i in range (self.K):\n",
    "            for j in range (self.E_dim):\n",
    "                iter=int(v_times_prediction[i])\n",
    "                matrix_prediction[i][j]= self.matrix[iter][j]\n",
    "         \n",
    "        #Making the exponential average\n",
    "        for i in range (self.E_dim): \n",
    "            sum=0.\n",
    "            den=0.\n",
    "            for j in range (self.K):\n",
    "                sum+=matrix_prediction[j][i]*math.exp(-distance[j])\n",
    "                den+=math.exp(-distance[j])\n",
    "            sum = sum/den\n",
    "            prediction[i]=sum\n",
    "            \n",
    "        return prediction \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE RECURRENT NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation of a recurrent neural netwotk (RNN) I followed the tutorial at [this link](https://www.guru99.com/rnn-tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/lucazilli/miniconda3/envs/calcolo/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# compose the NN model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras import optimizers, losses, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB\n",
    "check the version of tensorflow. the programme needs the version 1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "step_futuro=4\n",
    "n_windows = 100   \n",
    "n_input =  1\n",
    "n_output = 1\n",
    "size_train = 10000+step_futuro\n",
    "size_test=3000+step_futuro\n",
    "print(f'size_train {size_train}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "train_set = nord_volumes[:size_train]\n",
    "test_set = nord_volumes[size_train:size_test+size_train]\n",
    "    \n",
    "X_batches, y_batches = create_batches(df = train_set,\n",
    "                                windows = n_windows,\n",
    "                                input = n_input,\n",
    "                                output = n_output,\n",
    "                                step_f=step_futuro,\n",
    "                                size=size_train)\n",
    "    \n",
    "X_test, y_test = create_batches(df = test_set,\n",
    "                                windows = n_windows,\n",
    "                                input = n_input,\n",
    "                                output = n_output,\n",
    "                                step_f=step_futuro,\n",
    "                                size=size_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the RNN\n",
    "tf.reset_default_graph()\n",
    "r_neuron = 1000    \n",
    "\n",
    "## 1. Construct the tensors\n",
    "X = tf.placeholder(tf.float32, [None, n_windows, n_input])   \n",
    "y = tf.placeholder(tf.float32, [None, n_windows, n_output])\n",
    "\n",
    "## 2. create the model\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=r_neuron, activation=tf.nn.relu)\n",
    "rnn_output, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "\n",
    "stacked_rnn_output = tf.reshape(rnn_output, [-1, r_neuron])          \n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_output, n_output)       \n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_windows, n_output])   \n",
    "\n",
    "## 3. Loss + optimization\n",
    "learning_rate = 0.001  \n",
    " \n",
    "loss = tf.reduce_sum(tf.square(outputs - y))    \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)         \n",
    "training_op = optimizer.minimize(loss)                                          \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "iteration = 150\n",
    "it_print=10\n",
    "mse_train_array=[]\n",
    "mse_test_array=[]\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iters in range(iteration):\n",
    "        sess.run(training_op, feed_dict={X: X_batches, y: y_batches})\n",
    "        if iters % it_print == 0:\n",
    "            mse_train = loss.eval(feed_dict={X: X_batches, y: y_batches})\n",
    "            mse_train_array.append(mse_train)\n",
    "            mse_test = loss.eval(feed_dict={X: X_test, y: y_test})\n",
    "            mse_test_array.append(mse_test)\n",
    "            print(iters, \"\\tMSE E_in:\", mse_train)\n",
    "            print(iters, \"\\tMSE E_out:\", mse_test)\n",
    "    \n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_test})\n",
    "                                      \n",
    "# y_pred contains the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the MSE as function of the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(30, 22))\n",
    "\n",
    "\n",
    "plt.plot(np.arange(np.asarray(mse_test_array).size)[:]*it_print,mse_test_array[:],label=\"test\")\n",
    "plt.plot(np.arange(np.asarray(mse_train_array).size)[:]*it_print,mse_train_array[:],label=\"train\")\n",
    "\n",
    "# add legend\n",
    "leg = ax.legend(loc=(0.4, 0.75),frameon=True,prop={'size': 80})\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(3)\n",
    "\n",
    "plt.grid(True)\n",
    "# add labels for axes\n",
    "ax.set_xlabel(\"iterations\")\n",
    "plt.ylabel('MSE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Forcast vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(30, 22))\n",
    "plt.title(\"Forecast vs Actual\", fontsize=100)\n",
    "plt.plot(pd.Series(np.ravel(y_test)), \"bo\", markersize=40, label=\"Actual\", color='green')\n",
    "plt.plot(pd.Series(np.ravel(y_pred)), \"r.\", markersize=40, label=\"Forecast\", color='red')\n",
    "\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.xlabel(f'Time')\n",
    "plt.ylabel(f'Energy [kWh]')\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
